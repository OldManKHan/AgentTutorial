# 第五章：记忆系统

> 🎯 本章目标：理解 Agent 记忆系统的设计原理，掌握向量数据库和 RAG 技术，学会为 Agent 添加长期记忆能力

## 为什么 Agent 需要记忆？

想象一下，你每天都和同一个助手对话，但每次对话开始时，他都完全不记得之前的交流。你需要反复解释你的偏好、项目背景、工作习惯...

这就是没有记忆系统的 Agent 面临的困境。

```
┌─────────────────────────────────────────────────────────────┐
│                    Agent 记忆的价值                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  没有记忆的 Agent：                                         │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  Day 1: "我喜欢用 TypeScript，项目用 Bun 构建"      │   │
│  │  Day 2: "请问你用什么语言？什么构建工具？"          │   │
│  │  Day 3: "你的技术栈是什么？"                        │   │
│  │  ...每次都要重新介绍 😫                             │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  有记忆的 Agent：                                           │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  Day 1: "我喜欢用 TypeScript，项目用 Bun 构建"      │   │
│  │  Day 2: "好的，我用 TypeScript 和 Bun 帮你写代码"   │   │
│  │  Day 3: "基于你之前的偏好，我建议..."               │   │
│  │  ...持续积累，越来越懂你 🎉                         │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 记忆解决的核心问题

| 问题 | 没有记忆 | 有记忆 |
|------|----------|--------|
| 上下文窗口限制 | 超出窗口的信息丢失 | 重要信息持久化存储 |
| 跨会话连续性 | 每次对话从零开始 | 延续之前的上下文 |
| 知识积累 | 无法学习用户偏好 | 逐渐了解用户习惯 |
| 个性化服务 | 千人一面的回答 | 针对性的建议 |
| 长期任务 | 无法追踪进度 | 记住任务状态和历史 |

---

## 1. 记忆类型

人类的记忆系统是复杂的，Agent 的记忆系统也需要多种类型来满足不同需求。


```
┌─────────────────────────────────────────────────────────────┐
│                    Agent 记忆类型体系                       │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  按持续时间分类：                                           │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                                                     │   │
│  │  短期记忆 (Short-term Memory)                       │   │
│  │  ├── 当前对话上下文                                 │   │
│  │  ├── 最近几轮的交互                                 │   │
│  │  └── 生命周期：单次会话                             │   │
│  │                                                     │   │
│  │  工作记忆 (Working Memory)                          │   │
│  │  ├── 当前任务的状态                                 │   │
│  │  ├── 正在处理的信息                                 │   │
│  │  └── 生命周期：任务执行期间                         │   │
│  │                                                     │   │
│  │  长期记忆 (Long-term Memory)                        │   │
│  │  ├── 用户偏好和习惯                                 │   │
│  │  ├── 历史对话摘要                                   │   │
│  │  ├── 学到的知识                                     │   │
│  │  └── 生命周期：永久（除非主动删除）                 │   │
│  │                                                     │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  按内容类型分类：                                           │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                                                     │   │
│  │  情景记忆 (Episodic Memory)                         │   │
│  │  ├── 具体的事件和经历                               │   │
│  │  ├── "上周二我们讨论了 API 设计"                    │   │
│  │  └── 带有时间和上下文信息                           │   │
│  │                                                     │   │
│  │  语义记忆 (Semantic Memory)                         │   │
│  │  ├── 抽象的知识和事实                               │   │
│  │  ├── "用户偏好 TypeScript"                          │   │
│  │  └── 不依赖具体事件                                 │   │
│  │                                                     │   │
│  │  程序记忆 (Procedural Memory)                       │   │
│  │  ├── 如何执行任务的知识                             │   │
│  │  ├── "部署流程：先测试，再构建，最后发布"           │   │
│  │  └── 技能和流程                                     │   │
│  │                                                     │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 1.1 短期记忆

短期记忆就是我们在[第一章](./01-context-engineering.md)讨论的上下文窗口内容。

```typescript
// 短期记忆示例：当前对话历史
interface ShortTermMemory {
  messages: Message[]        // 当前会话的消息列表
  maxTokens: number          // 上下文窗口限制
  currentTokens: number      // 当前使用的 Token 数
}

// 特点：
// - 容量有限（受上下文窗口限制）
// - 访问速度快（直接在 Prompt 中）
// - 会话结束后丢失
```

### 1.2 工作记忆

工作记忆是 Agent 执行任务时的"草稿纸"，存储当前任务的状态和中间结果。

```typescript
// 工作记忆示例：任务执行状态
interface WorkingMemory {
  currentTask: string           // 当前任务描述
  subtasks: Subtask[]           // 子任务列表
  completedSteps: string[]      // 已完成的步骤
  pendingDecisions: Decision[]  // 待决策的问题
  scratchpad: string            // 思考过程记录
}

// 特点：
// - 任务相关
// - 动态更新
// - 任务完成后可归档或丢弃
```

### 1.3 长期记忆

长期记忆是 Agent 的"知识库"，存储需要跨会话保留的信息。

```typescript
// 长期记忆示例
interface LongTermMemory {
  // 用户画像
  userProfile: {
    preferences: Record<string, string>  // 偏好设置
    skills: string[]                      // 技术栈
    workStyle: string                     // 工作风格
  }
  
  // 项目知识
  projectKnowledge: {
    architecture: string      // 架构说明
    conventions: string[]     // 代码规范
    commonPatterns: string[]  // 常用模式
  }
  
  // 历史摘要
  conversationSummaries: Summary[]  // 历史对话摘要
}

// 特点：
// - 持久化存储
// - 需要检索机制
// - 需要更新和遗忘机制
```

### 记忆类型对比

| 类型 | 容量 | 持续时间 | 访问方式 | 典型用途 |
|------|------|----------|----------|----------|
| 短期记忆 | 小（上下文窗口） | 单次会话 | 直接包含在 Prompt | 当前对话上下文 |
| 工作记忆 | 中 | 任务期间 | 按需加载 | 任务状态追踪 |
| 长期记忆 | 大（理论无限） | 永久 | 检索 | 用户偏好、知识库 |
| 情景记忆 | 大 | 永久 | 时间/事件检索 | 历史事件回顾 |
| 语义记忆 | 大 | 永久 | 语义检索 | 知识问答 |

---

## 2. 向量数据库

长期记忆需要高效的存储和检索机制。向量数据库是目前最流行的解决方案。

### 2.1 为什么需要向量数据库？

传统数据库使用关键词匹配，但自然语言的表达方式多样：

```
┌─────────────────────────────────────────────────────────────┐
│                关键词搜索 vs 语义搜索                       │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  用户查询："如何让代码跑得更快？"                           │
│                                                             │
│  关键词搜索：                                               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  搜索关键词：["代码", "跑", "快"]                   │   │
│  │                                                     │   │
│  │  ❌ 找不到："性能优化技巧"                          │   │
│  │  ❌ 找不到："提升程序效率的方法"                    │   │
│  │  ❌ 找不到："Performance optimization guide"        │   │
│  │                                                     │   │
│  │  问题：同义词、不同表达方式无法匹配                 │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  语义搜索（向量数据库）：                                   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  查询向量：[0.2, -0.5, 0.8, ...]  (语义表示)        │   │
│  │                                                     │   │
│  │  ✅ 匹配："性能优化技巧"         (相似度: 0.92)     │   │
│  │  ✅ 匹配："提升程序效率的方法"   (相似度: 0.89)     │   │
│  │  ✅ 匹配："Performance optimization" (相似度: 0.85) │   │
│  │                                                     │   │
│  │  优势：理解语义，跨语言，同义词匹配                 │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 2.2 Embedding 原理

Embedding（嵌入）是将文本转换为向量的过程。

```
┌─────────────────────────────────────────────────────────────┐
│                    Embedding 过程                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  文本 ──────► Embedding 模型 ──────► 向量                   │
│                                                             │
│  示例：                                                     │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  "我喜欢编程"                                       │   │
│  │       │                                             │   │
│  │       ▼                                             │   │
│  │  [0.12, -0.45, 0.78, 0.23, -0.56, ...]             │   │
│  │  (1536 维向量，OpenAI text-embedding-3-small)       │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  语义相似的文本，向量也相似：                               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  "我喜欢编程"     → [0.12, -0.45, 0.78, ...]        │   │
│  │  "我热爱写代码"   → [0.11, -0.44, 0.79, ...]  相似! │   │
│  │  "今天天气真好"   → [0.89, 0.23, -0.12, ...]  不同  │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  相似度计算（余弦相似度）：                                 │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  similarity = cos(θ) = (A · B) / (|A| × |B|)        │   │
│  │                                                     │   │
│  │  范围：[-1, 1]                                      │   │
│  │  1 = 完全相同，0 = 无关，-1 = 完全相反              │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 2.3 常见 Embedding 模型

| 模型 | 维度 | 特点 | 价格 |
|------|------|------|------|
| OpenAI text-embedding-3-small | 1536 | 性价比高 | $0.02/1M tokens |
| OpenAI text-embedding-3-large | 3072 | 精度更高 | $0.13/1M tokens |
| Cohere embed-v3 | 1024 | 多语言支持好 | $0.10/1M tokens |
| Voyage AI voyage-2 | 1024 | 代码理解强 | $0.10/1M tokens |
| BGE-M3 (开源) | 1024 | 免费，多语言 | 免费 |
| Jina Embeddings (开源) | 768 | 免费，轻量 | 免费 |


### 2.4 常见向量数据库对比

```
┌─────────────────────────────────────────────────────────────┐
│                    向量数据库选型                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  云服务（托管）：                                           │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  Pinecone                                           │   │
│  │  ├── 优点：全托管，易用，性能好                     │   │
│  │  ├── 缺点：成本较高，数据在云端                     │   │
│  │  └── 适合：生产环境，快速上手                       │   │
│  │                                                     │   │
│  │  Weaviate Cloud                                     │   │
│  │  ├── 优点：支持混合搜索，GraphQL API                │   │
│  │  ├── 缺点：学习曲线稍陡                             │   │
│  │  └── 适合：复杂查询需求                             │   │
│  │                                                     │   │
│  │  Qdrant Cloud                                       │   │
│  │  ├── 优点：性能优秀，过滤能力强                     │   │
│  │  ├── 缺点：生态相对较新                             │   │
│  │  └── 适合：高性能需求                               │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  自托管（开源）：                                           │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  Chroma                                             │   │
│  │  ├── 优点：轻量，Python 友好，易于嵌入              │   │
│  │  ├── 缺点：大规模性能一般                           │   │
│  │  └── 适合：原型开发，小规模应用                     │   │
│  │                                                     │   │
│  │  Milvus                                             │   │
│  │  ├── 优点：高性能，支持大规模                       │   │
│  │  ├── 缺点：部署复杂                                 │   │
│  │  └── 适合：大规模生产环境                           │   │
│  │                                                     │   │
│  │  pgvector (PostgreSQL 扩展)                         │   │
│  │  ├── 优点：与现有 PG 集成，SQL 查询                 │   │
│  │  ├── 缺点：性能不如专用数据库                       │   │
│  │  └── 适合：已有 PostgreSQL 的项目                   │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

| 数据库 | 类型 | 语言 | 特点 | 推荐场景 |
|--------|------|------|------|----------|
| Pinecone | 云服务 | 任意 | 全托管，简单易用 | 快速上线 |
| Chroma | 开源 | Python | 轻量，嵌入式 | 原型开发 |
| Qdrant | 开源/云 | Rust | 高性能，过滤强 | 生产环境 |
| Weaviate | 开源/云 | Go | 混合搜索，GraphQL | 复杂查询 |
| Milvus | 开源 | Go/C++ | 大规模，分布式 | 企业级 |
| pgvector | 扩展 | SQL | PostgreSQL 集成 | 已有 PG |

### 2.5 向量索引与检索

向量数据库使用特殊的索引结构来加速相似度搜索：

```
┌─────────────────────────────────────────────────────────────┐
│                    向量索引类型                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  暴力搜索 (Brute Force)：                                   │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  • 计算查询向量与所有向量的相似度                   │   │
│  │  • 时间复杂度：O(n)                                 │   │
│  │  • 精确但慢，适合小数据集                           │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  HNSW (Hierarchical Navigable Small World)：                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  • 构建多层图结构                                   │   │
│  │  • 从顶层快速定位，逐层细化                         │   │
│  │  • 时间复杂度：O(log n)                             │   │
│  │  • 最常用，平衡速度和精度                           │   │
│  │                                                     │   │
│  │  Layer 2:  ○───────○───────○                        │   │
│  │            │       │       │                        │   │
│  │  Layer 1:  ○───○───○───○───○───○                    │   │
│  │            │   │   │   │   │   │                    │   │
│  │  Layer 0:  ○─○─○─○─○─○─○─○─○─○─○─○                  │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  IVF (Inverted File Index)：                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  • 将向量空间划分为多个聚类                         │   │
│  │  • 只搜索最近的几个聚类                             │   │
│  │  • 适合大规模数据                                   │   │
│  │                                                     │   │
│  │  ┌─────┐  ┌─────┐  ┌─────┐                         │   │
│  │  │ C1  │  │ C2  │  │ C3  │  聚类中心               │   │
│  │  │ ○○○ │  │ ○○  │  │ ○○○○│  各聚类的向量           │   │
│  │  └─────┘  └─────┘  └─────┘                         │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 3. RAG 与 Agent 结合

RAG（Retrieval-Augmented Generation，检索增强生成）是将记忆系统与 LLM 结合的关键技术。

### 3.1 RAG 基本架构

```
┌─────────────────────────────────────────────────────────────┐
│                    RAG 工作流程                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  离线阶段（索引构建）：                                     │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                                                     │   │
│  │  文档 ──► 分块 ──► Embedding ──► 向量数据库         │   │
│  │                                                     │   │
│  │  "用户手册.pdf"                                     │   │
│  │       │                                             │   │
│  │       ▼                                             │   │
│  │  [chunk1, chunk2, chunk3, ...]                      │   │
│  │       │                                             │   │
│  │       ▼                                             │   │
│  │  [[0.1, 0.2, ...], [0.3, 0.4, ...], ...]           │   │
│  │       │                                             │   │
│  │       ▼                                             │   │
│  │  存入向量数据库                                     │   │
│  │                                                     │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  在线阶段（查询处理）：                                     │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                                                     │   │
│  │  用户问题 ──► Embedding ──► 向量搜索 ──► 相关文档   │   │
│  │                                    │                │   │
│  │                                    ▼                │   │
│  │  [问题 + 相关文档] ──────────────► LLM ──► 回答     │   │
│  │                                                     │   │
│  │  示例：                                             │   │
│  │  Q: "如何配置数据库连接？"                          │   │
│  │       │                                             │   │
│  │       ▼ (向量搜索)                                  │   │
│  │  找到：[数据库配置章节, 连接池说明, 示例代码]       │   │
│  │       │                                             │   │
│  │       ▼ (组合 Prompt)                               │   │
│  │  "根据以下文档回答问题：                            │   │
│  │   [文档内容...]                                     │   │
│  │   问题：如何配置数据库连接？"                       │   │
│  │       │                                             │   │
│  │       ▼ (LLM 生成)                                  │   │
│  │  "要配置数据库连接，你需要..."                      │   │
│  │                                                     │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 3.2 文档分块策略

分块（Chunking）是 RAG 的关键步骤，影响检索质量：

```
┌─────────────────────────────────────────────────────────────┐
│                    分块策略对比                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  固定大小分块：                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  原文：[████████████████████████████████████]       │   │
│  │  分块：[████] [████] [████] [████] [████]           │   │
│  │                                                     │   │
│  │  优点：简单，大小一致                               │   │
│  │  缺点：可能切断语义                                 │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  重叠分块：                                                 │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  原文：[████████████████████████████████████]       │   │
│  │  分块：[██████]                                     │   │
│  │           [██████]                                  │   │
│  │              [██████]                               │   │
│  │                                                     │   │
│  │  优点：保留上下文连续性                             │   │
│  │  缺点：存储冗余                                     │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  语义分块：                                                 │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  原文：[段落1][段落2][段落3][段落4]                 │   │
│  │  分块：[段落1+2] [段落3] [段落4]                    │   │
│  │        (按语义边界分割)                             │   │
│  │                                                     │   │
│  │  优点：语义完整                                     │   │
│  │  缺点：实现复杂，大小不一                           │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  递归分块：                                                 │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  先按大分隔符（章节）分                             │   │
│  │  如果太大，再按小分隔符（段落）分                   │   │
│  │  如果还太大，再按句子分                             │   │
│  │                                                     │   │
│  │  优点：尽量保持语义完整                             │   │
│  │  缺点：实现较复杂                                   │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

| 策略 | 实现复杂度 | 语义完整性 | 存储效率 | 推荐场景 |
|------|------------|------------|----------|----------|
| 固定大小 | 低 | 低 | 高 | 快速原型 |
| 重叠分块 | 低 | 中 | 中 | 通用场景 |
| 语义分块 | 高 | 高 | 高 | 高质量需求 |
| 递归分块 | 中 | 高 | 高 | 结构化文档 |


### 3.3 Agent 中的 RAG 集成

将 RAG 集成到 Agent 中，可以让 Agent 访问外部知识：

```
┌─────────────────────────────────────────────────────────────┐
│                Agent + RAG 架构                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                    Agent Core                        │   │
│  │                                                     │   │
│  │  ┌───────────────────────────────────────────────┐ │   │
│  │  │              Tool: memory_search               │ │   │
│  │  │                                               │ │   │
│  │  │  输入：query (搜索查询)                       │ │   │
│  │  │  输出：相关记忆片段                           │ │   │
│  │  │                                               │ │   │
│  │  │  实现：                                       │ │   │
│  │  │  1. 将 query 转为向量                         │ │   │
│  │  │  2. 在向量数据库中搜索                        │ │   │
│  │  │  3. 返回 top-k 相关结果                       │ │   │
│  │  └───────────────────────────────────────────────┘ │   │
│  │                                                     │   │
│  │  ┌───────────────────────────────────────────────┐ │   │
│  │  │              Tool: memory_store                │ │   │
│  │  │                                               │ │   │
│  │  │  输入：content (要存储的内容)                 │ │   │
│  │  │        metadata (元数据)                      │ │   │
│  │  │  输出：存储确认                               │ │   │
│  │  │                                               │ │   │
│  │  │  实现：                                       │ │   │
│  │  │  1. 将 content 转为向量                       │ │   │
│  │  │  2. 存入向量数据库                            │ │   │
│  │  │  3. 返回存储 ID                               │ │   │
│  │  └───────────────────────────────────────────────┘ │   │
│  │                                                     │   │
│  └─────────────────────────────────────────────────────┘   │
│                          │                                  │
│                          ▼                                  │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                  向量数据库                          │   │
│  │  ┌─────────────────────────────────────────────┐   │   │
│  │  │  用户偏好 | 项目知识 | 历史对话 | 文档库    │   │   │
│  │  └─────────────────────────────────────────────┘   │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 4. 记忆检索策略

检索质量直接影响 Agent 的回答质量。好的检索策略需要考虑多个维度。

### 4.1 相似度检索

最基本的检索方式，基于向量相似度：

```typescript
// 基本相似度检索
async function similaritySearch(query: string, topK: number = 5) {
  // 1. 将查询转为向量
  const queryVector = await embed(query)
  
  // 2. 在向量数据库中搜索
  const results = await vectorDB.search({
    vector: queryVector,
    topK: topK,
    // 可选：添加过滤条件
    filter: {
      type: "user_preference"  // 只搜索用户偏好类型
    }
  })
  
  return results
}
```

### 4.2 时间衰减

越新的记忆通常越相关：

```
┌─────────────────────────────────────────────────────────────┐
│                    时间衰减策略                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  最终得分 = 相似度得分 × 时间衰减因子                       │
│                                                             │
│  时间衰减函数：                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                                                     │   │
│  │  指数衰减：decay = e^(-λ × age)                     │   │
│  │                                                     │   │
│  │  得分                                               │   │
│  │  1.0 ┤ ●                                            │   │
│  │      │  ●                                           │   │
│  │  0.5 ┤    ●                                         │   │
│  │      │       ●                                      │   │
│  │  0.0 ┤          ●────●────●────                     │   │
│  │      └────┬────┬────┬────┬────► 时间               │   │
│  │          1天  7天  30天 90天                        │   │
│  │                                                     │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  示例代码：                                                 │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  function timeDecay(timestamp: number): number {    │   │
│  │    const ageInDays = (Date.now() - timestamp)       │   │
│  │                      / (1000 * 60 * 60 * 24)        │   │
│  │    const lambda = 0.1  // 衰减系数                  │   │
│  │    return Math.exp(-lambda * ageInDays)             │   │
│  │  }                                                  │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 4.3 重要性排序

不是所有记忆都同等重要：

```typescript
// 记忆重要性评估
interface Memory {
  content: string
  vector: number[]
  metadata: {
    timestamp: number
    accessCount: number    // 被访问次数
    source: string         // 来源（用户明确说明 vs 推断）
    confidence: number     // 置信度
    type: "preference" | "fact" | "episode"
  }
}

function calculateImportance(memory: Memory): number {
  let score = 0
  
  // 访问频率加分
  score += Math.log(memory.metadata.accessCount + 1) * 0.2
  
  // 用户明确说明的更重要
  if (memory.metadata.source === "explicit") {
    score += 0.3
  }
  
  // 高置信度加分
  score += memory.metadata.confidence * 0.2
  
  // 偏好类型更重要
  if (memory.metadata.type === "preference") {
    score += 0.2
  }
  
  return score
}
```

### 4.4 混合检索

结合多种检索方式获得最佳结果：

```
┌─────────────────────────────────────────────────────────────┐
│                    混合检索策略                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  查询："用户之前说过喜欢什么编程语言？"                     │
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  1. 向量相似度搜索                                  │   │
│  │     → 找到语义相关的记忆                            │   │
│  │     结果：["喜欢 TypeScript", "用过 Python", ...]   │   │
│  │                                                     │   │
│  │  2. 关键词搜索                                      │   │
│  │     → 精确匹配关键词                                │   │
│  │     结果：["编程语言偏好：TypeScript"]              │   │
│  │                                                     │   │
│  │  3. 元数据过滤                                      │   │
│  │     → 只看 type="preference" 的记忆                 │   │
│  │     结果：过滤后的偏好记忆                          │   │
│  │                                                     │   │
│  │  4. 融合排序                                        │   │
│  │     → 综合考虑相似度、时间、重要性                  │   │
│  │     最终结果：["TypeScript 是首选语言"]             │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  融合公式：                                                 │
│  final_score = α × similarity                               │
│              + β × keyword_match                            │
│              + γ × time_decay                               │
│              + δ × importance                               │
│                                                             │
│  其中 α + β + γ + δ = 1                                     │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 5. 遗忘与更新机制

记忆系统不能只增不减，需要合理的遗忘和更新机制。

### 5.1 为什么需要遗忘？

```
┌─────────────────────────────────────────────────────────────┐
│                    遗忘的必要性                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  问题 1：存储成本                                           │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  无限积累 → 存储成本线性增长                        │   │
│  │  向量数据库按存储量计费                             │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  问题 2：检索效率                                           │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  数据量越大 → 检索越慢                              │   │
│  │  噪声越多 → 相关结果被淹没                          │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  问题 3：信息过时                                           │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  旧记忆："用户喜欢 JavaScript"                      │   │
│  │  新记忆："用户现在更喜欢 TypeScript"                │   │
│  │  如果不更新，可能给出过时的建议                     │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  问题 4：矛盾信息                                           │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  记忆 A："项目使用 MySQL"                           │   │
│  │  记忆 B："项目迁移到了 PostgreSQL"                  │   │
│  │  需要识别并解决矛盾                                 │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 5.2 遗忘策略

```typescript
// 遗忘策略实现
interface ForgetPolicy {
  // 基于时间的遗忘
  maxAge?: number           // 最大保留时间（天）
  
  // 基于访问的遗忘
  minAccessCount?: number   // 最小访问次数
  accessWindow?: number     // 访问统计窗口（天）
  
  // 基于容量的遗忘
  maxMemories?: number      // 最大记忆数量
  
  // 基于重要性的遗忘
  minImportance?: number    // 最小重要性阈值
}

async function applyForgetPolicy(policy: ForgetPolicy) {
  const memories = await getAllMemories()
  const toDelete: string[] = []
  
  for (const memory of memories) {
    // 检查时间
    if (policy.maxAge) {
      const ageInDays = (Date.now() - memory.timestamp) / (1000 * 60 * 60 * 24)
      if (ageInDays > policy.maxAge) {
        toDelete.push(memory.id)
        continue
      }
    }
    
    // 检查访问频率
    if (policy.minAccessCount && policy.accessWindow) {
      const recentAccess = memory.accessHistory.filter(
        t => (Date.now() - t) < policy.accessWindow * 24 * 60 * 60 * 1000
      ).length
      if (recentAccess < policy.minAccessCount) {
        toDelete.push(memory.id)
        continue
      }
    }
    
    // 检查重要性
    if (policy.minImportance) {
      if (calculateImportance(memory) < policy.minImportance) {
        toDelete.push(memory.id)
      }
    }
  }
  
  // 容量限制：删除最不重要的
  if (policy.maxMemories && memories.length > policy.maxMemories) {
    const sorted = memories
      .filter(m => !toDelete.includes(m.id))
      .sort((a, b) => calculateImportance(a) - calculateImportance(b))
    
    const excess = sorted.length - policy.maxMemories
    for (let i = 0; i < excess; i++) {
      toDelete.push(sorted[i].id)
    }
  }
  
  // 执行删除
  await deleteMemories(toDelete)
}
```

### 5.3 更新策略

当新信息与旧记忆冲突时，需要更新：

```
┌─────────────────────────────────────────────────────────────┐
│                    记忆更新流程                             │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  新信息："用户现在使用 Bun 而不是 Node.js"                  │
│                                                             │
│  1. 检测冲突                                                │
│     ┌─────────────────────────────────────────────────┐    │
│     │  搜索相关记忆                                   │    │
│     │  → 找到："用户使用 Node.js 作为运行时"          │    │
│     │  → 检测到冲突（同一主题，不同值）               │    │
│     └─────────────────────────────────────────────────┘    │
│                          │                                  │
│                          ▼                                  │
│  2. 决定处理方式                                            │
│     ┌─────────────────────────────────────────────────┐    │
│     │  选项 A：替换旧记忆                             │    │
│     │  选项 B：标记旧记忆为过时，添加新记忆           │    │
│     │  选项 C：合并（保留历史变化）                   │    │
│     └─────────────────────────────────────────────────┘    │
│                          │                                  │
│                          ▼                                  │
│  3. 执行更新                                                │
│     ┌─────────────────────────────────────────────────┐    │
│     │  旧记忆：{                                      │    │
│     │    content: "用户使用 Node.js",                 │    │
│     │    status: "outdated",  // 标记为过时           │    │
│     │    supersededBy: "memory_123"                   │    │
│     │  }                                              │    │
│     │                                                 │    │
│     │  新记忆：{                                      │    │
│     │    id: "memory_123",                            │    │
│     │    content: "用户使用 Bun 作为运行时",          │    │
│     │    supersedes: "memory_456"                     │    │
│     │  }                                              │    │
│     └─────────────────────────────────────────────────┘    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```


---

## 6. 实践案例

由于 OpenCode 目前主要使用基于文件的简单存储（`storage/storage.ts`），没有完整的向量数据库记忆系统，我们将参考 LangChain 和 LlamaIndex 的实现来学习最佳实践。

### 6.1 OpenCode 基础存储分析

OpenCode 的存储模块提供了基础的持久化能力：

```typescript
// packages/opencode/src/storage/storage.ts（简化版）

export namespace Storage {
  // 存储目录结构
  // ~/.opencode/storage/
  //   ├── project/          # 项目信息
  //   ├── session/          # 会话数据
  //   ├── message/          # 消息历史
  //   └── part/             # 消息部分

  // 读取存储的数据
  // key 是路径数组，如 ["session", "project123", "session456"]
  export async function read<T>(key: string[]) {
    const dir = await state().then((x) => x.dir)
    const target = path.join(dir, ...key) + ".json"
    
    return withErrorHandling(async () => {
      // 使用读锁保证并发安全
      using _ = await Lock.read(target)
      const result = await Bun.file(target).json()
      return result as T
    })
  }

  // 写入数据
  export async function write<T>(key: string[], content: T) {
    const dir = await state().then((x) => x.dir)
    const target = path.join(dir, ...key) + ".json"
    
    return withErrorHandling(async () => {
      // 使用写锁保证并发安全
      using _ = await Lock.write(target)
      await Bun.write(target, JSON.stringify(content, null, 2))
    })
  }

  // 列出某个前缀下的所有数据
  export async function list(prefix: string[]) {
    const dir = await state().then((x) => x.dir)
    try {
      const result = await Array.fromAsync(
        glob.scan({
          cwd: path.join(dir, ...prefix),
          onlyFiles: true,
        }),
      ).then((results) => 
        results.map((x) => [...prefix, ...x.slice(0, -5).split(path.sep)])
      )
      result.sort()
      return result
    } catch {
      return []
    }
  }
}
```

**关键设计点**：
1. **基于文件系统**：简单可靠，无需额外依赖
2. **JSON 格式**：易于调试和迁移
3. **锁机制**：保证并发安全
4. **路径即键**：直观的数据组织方式

**局限性**：
- 不支持语义搜索
- 不适合大规模数据
- 没有向量索引能力

### 6.2 LangChain Memory 模块参考

LangChain 提供了丰富的记忆组件，是学习记忆系统设计的好参考：

```typescript
// LangChain 记忆系统架构（概念示例）

// 1. 基础记忆接口
interface BaseMemory {
  // 加载记忆变量到上下文
  loadMemoryVariables(inputs: Record<string, any>): Promise<Record<string, any>>
  
  // 保存上下文到记忆
  saveContext(
    inputs: Record<string, any>, 
    outputs: Record<string, any>
  ): Promise<void>
  
  // 清除记忆
  clear(): Promise<void>
}

// 2. 对话缓冲记忆（最简单的实现）
// 保存完整的对话历史
class ConversationBufferMemory implements BaseMemory {
  private messages: Message[] = []
  
  async loadMemoryVariables() {
    return {
      history: this.messages.map(m => `${m.role}: ${m.content}`).join('\n')
    }
  }
  
  async saveContext(inputs: any, outputs: any) {
    this.messages.push({ role: 'human', content: inputs.input })
    this.messages.push({ role: 'ai', content: outputs.output })
  }
}

// 3. 对话摘要记忆
// 使用 LLM 生成对话摘要，节省 Token
class ConversationSummaryMemory implements BaseMemory {
  private summary: string = ""
  private llm: LLM
  
  async loadMemoryVariables() {
    return { history: this.summary }
  }
  
  async saveContext(inputs: any, outputs: any) {
    // 使用 LLM 更新摘要
    // 将新对话与现有摘要合并
    this.summary = await this.llm.summarize(
      this.summary,
      inputs.input,
      outputs.output
    )
  }
}

// 4. 向量存储记忆
// 使用向量数据库存储和检索记忆
class VectorStoreMemory implements BaseMemory {
  private vectorStore: VectorStore
  private embeddings: Embeddings
  
  async loadMemoryVariables(inputs: any) {
    // 根据当前输入检索相关记忆
    const query = inputs.input
    const relevantDocs = await this.vectorStore.similaritySearch(query, 5)
    
    return {
      history: relevantDocs.map(d => d.pageContent).join('\n')
    }
  }
  
  async saveContext(inputs: any, outputs: any) {
    // 将对话存入向量数据库
    const content = `Human: ${inputs.input}\nAI: ${outputs.output}`
    const vector = await this.embeddings.embed(content)
    
    await this.vectorStore.addDocuments([{
      pageContent: content,
      metadata: { timestamp: Date.now() }
    }])
  }
}
```

**LangChain 记忆类型对比**：

| 类型 | 存储方式 | Token 使用 | 适用场景 |
|------|----------|------------|----------|
| BufferMemory | 完整历史 | 高 | 短对话 |
| BufferWindowMemory | 最近 N 轮 | 中 | 中等对话 |
| SummaryMemory | 摘要 | 低 | 长对话 |
| VectorStoreMemory | 向量检索 | 低 | 大量历史 |
| EntityMemory | 实体提取 | 中 | 需要追踪实体 |

### 6.3 LlamaIndex 检索系统参考

LlamaIndex 专注于 RAG 系统，提供了强大的检索能力：

```typescript
// LlamaIndex 核心概念（概念示例）

// 1. 文档加载和分块
class SimpleDirectoryReader {
  // 从目录加载文档
  async loadData(directory: string): Promise<Document[]> {
    const files = await readDir(directory)
    return files.map(file => new Document({
      text: readFile(file),
      metadata: { source: file }
    }))
  }
}

// 2. 索引构建
class VectorStoreIndex {
  private vectorStore: VectorStore
  private embedModel: EmbedModel
  
  // 从文档构建索引
  static async fromDocuments(
    documents: Document[],
    options: { embedModel: EmbedModel, vectorStore: VectorStore }
  ) {
    const index = new VectorStoreIndex()
    
    for (const doc of documents) {
      // 分块
      const chunks = splitDocument(doc, { chunkSize: 512, overlap: 50 })
      
      // 生成向量
      for (const chunk of chunks) {
        const vector = await options.embedModel.embed(chunk.text)
        await options.vectorStore.add({
          id: generateId(),
          vector,
          text: chunk.text,
          metadata: chunk.metadata
        })
      }
    }
    
    return index
  }
  
  // 创建查询引擎
  asQueryEngine(): QueryEngine {
    return new QueryEngine(this)
  }
}

// 3. 查询引擎
class QueryEngine {
  private index: VectorStoreIndex
  private llm: LLM
  
  async query(question: string): Promise<Response> {
    // 检索相关文档
    const relevantDocs = await this.index.retrieve(question, { topK: 5 })
    
    // 构建 Prompt
    const context = relevantDocs.map(d => d.text).join('\n\n')
    const prompt = `
      Based on the following context, answer the question.
      
      Context:
      ${context}
      
      Question: ${question}
      
      Answer:
    `
    
    // 生成回答
    const answer = await this.llm.complete(prompt)
    
    return {
      response: answer,
      sourceNodes: relevantDocs
    }
  }
}

// 4. 使用示例
async function main() {
  // 加载文档
  const reader = new SimpleDirectoryReader()
  const documents = await reader.loadData('./docs')
  
  // 构建索引
  const index = await VectorStoreIndex.fromDocuments(documents, {
    embedModel: new OpenAIEmbedding(),
    vectorStore: new ChromaVectorStore()
  })
  
  // 查询
  const engine = index.asQueryEngine()
  const response = await engine.query("如何配置数据库连接？")
  
  console.log(response.response)
  console.log("Sources:", response.sourceNodes.map(n => n.metadata.source))
}
```

**LlamaIndex 核心组件**：

```
┌─────────────────────────────────────────────────────────────┐
│                LlamaIndex 架构                              │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │   Readers   │───►│   Nodes     │───►│   Index     │     │
│  │  (加载器)   │    │  (分块)     │    │  (索引)     │     │
│  └─────────────┘    └─────────────┘    └─────────────┘     │
│                                               │             │
│                                               ▼             │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │  Response   │◄───│  Retriever  │◄───│Query Engine │     │
│  │  (响应)     │    │  (检索器)   │    │ (查询引擎)  │     │
│  └─────────────┘    └─────────────┘    └─────────────┘     │
│                                                             │
│  关键特性：                                                 │
│  • 多种数据源支持（PDF、网页、数据库等）                   │
│  • 灵活的分块策略                                          │
│  • 多种索引类型（向量、关键词、知识图谱）                  │
│  • 可组合的查询管道                                        │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```


---

## 7. 动手实验

### 实验 1：Embedding 基础

**目标**：理解 Embedding 的工作原理和语义相似度

**步骤**：

1. 创建实验文件：

```typescript
// embedding-experiment.ts
import OpenAI from "openai"

const openai = new OpenAI()

// 生成文本的 Embedding
async function getEmbedding(text: string): Promise<number[]> {
  const response = await openai.embeddings.create({
    model: "text-embedding-3-small",
    input: text,
  })
  return response.data[0].embedding
}

// 计算余弦相似度
function cosineSimilarity(a: number[], b: number[]): number {
  let dotProduct = 0
  let normA = 0
  let normB = 0
  
  for (let i = 0; i < a.length; i++) {
    dotProduct += a[i] * b[i]
    normA += a[i] * a[i]
    normB += b[i] * b[i]
  }
  
  return dotProduct / (Math.sqrt(normA) * Math.sqrt(normB))
}

// 测试语义相似度
async function testSimilarity() {
  const texts = [
    "我喜欢编程",
    "我热爱写代码",
    "编程是我的爱好",
    "今天天气真好",
    "I love programming",
  ]
  
  console.log("生成 Embeddings...")
  const embeddings = await Promise.all(texts.map(getEmbedding))
  
  console.log("\n相似度矩阵：")
  console.log("".padEnd(20) + texts.map((_, i) => `[${i}]`.padStart(8)).join(""))
  
  for (let i = 0; i < texts.length; i++) {
    let row = `[${i}] ${texts[i]}`.padEnd(20)
    for (let j = 0; j < texts.length; j++) {
      const sim = cosineSimilarity(embeddings[i], embeddings[j])
      row += sim.toFixed(3).padStart(8)
    }
    console.log(row)
  }
}

testSimilarity()
```

2. 运行并观察结果：

```bash
bun run embedding-experiment.ts
```

3. 思考：
   - 哪些文本的相似度最高？
   - 中英文之间的相似度如何？
   - 语义相似但用词不同的文本，相似度是多少？

### 实验 2：简单向量存储

**目标**：实现一个简单的内存向量存储

**步骤**：

1. 创建向量存储类：

```typescript
// simple-vector-store.ts

interface VectorDocument {
  id: string
  text: string
  vector: number[]
  metadata: Record<string, any>
}

class SimpleVectorStore {
  private documents: VectorDocument[] = []
  
  // 添加文档
  add(doc: VectorDocument) {
    this.documents.push(doc)
    console.log(`Added document: ${doc.id}`)
  }
  
  // 相似度搜索
  search(queryVector: number[], topK: number = 5): VectorDocument[] {
    // 计算所有文档与查询的相似度
    const scored = this.documents.map(doc => ({
      doc,
      score: this.cosineSimilarity(queryVector, doc.vector)
    }))
    
    // 按相似度排序
    scored.sort((a, b) => b.score - a.score)
    
    // 返回 top-k
    return scored.slice(0, topK).map(s => {
      console.log(`  ${s.doc.id}: ${s.score.toFixed(4)}`)
      return s.doc
    })
  }
  
  private cosineSimilarity(a: number[], b: number[]): number {
    let dot = 0, normA = 0, normB = 0
    for (let i = 0; i < a.length; i++) {
      dot += a[i] * b[i]
      normA += a[i] * a[i]
      normB += b[i] * b[i]
    }
    return dot / (Math.sqrt(normA) * Math.sqrt(normB))
  }
  
  // 获取统计信息
  stats() {
    return {
      count: this.documents.length,
      dimensions: this.documents[0]?.vector.length || 0
    }
  }
}

// 测试
async function testVectorStore() {
  const store = new SimpleVectorStore()
  
  // 模拟一些记忆
  const memories = [
    { id: "1", text: "用户喜欢 TypeScript", metadata: { type: "preference" } },
    { id: "2", text: "项目使用 Bun 作为运行时", metadata: { type: "fact" } },
    { id: "3", text: "上周讨论了 API 设计", metadata: { type: "episode" } },
    { id: "4", text: "用户偏好函数式编程风格", metadata: { type: "preference" } },
    { id: "5", text: "数据库使用 PostgreSQL", metadata: { type: "fact" } },
  ]
  
  // 添加到存储（这里用随机向量模拟，实际应用中应使用 Embedding）
  for (const mem of memories) {
    store.add({
      ...mem,
      vector: Array.from({ length: 128 }, () => Math.random() - 0.5)
    })
  }
  
  console.log("\n存储统计:", store.stats())
  
  // 搜索（用随机向量模拟查询）
  console.log("\n搜索结果:")
  const queryVector = Array.from({ length: 128 }, () => Math.random() - 0.5)
  store.search(queryVector, 3)
}

testVectorStore()
```

2. 运行并观察搜索结果

3. 思考：如何改进这个简单实现？


### 实验 3：RAG 基础流程

**目标**：实现一个简单的 RAG 流程

**步骤**：

1. 创建 RAG 实验：

```typescript
// rag-experiment.ts
import OpenAI from "openai"

const openai = new OpenAI()

// 知识库（模拟）
const knowledgeBase = [
  {
    id: "doc1",
    content: "OpenCode 是一个开源的 AI 编程助手，使用 TypeScript 编写。",
    metadata: { source: "readme" }
  },
  {
    id: "doc2", 
    content: "OpenCode 支持多种 LLM 提供商，包括 OpenAI、Anthropic 和 Google。",
    metadata: { source: "docs" }
  },
  {
    id: "doc3",
    content: "要启动 OpenCode 开发服务器，在 packages/opencode 目录运行 bun dev。",
    metadata: { source: "contributing" }
  },
  {
    id: "doc4",
    content: "OpenCode 使用 MCP 协议来扩展工具能力，支持自定义 MCP 服务器。",
    metadata: { source: "docs" }
  },
]

// 简单的关键词检索（实际应用中应使用向量检索）
function retrieve(query: string, topK: number = 2): typeof knowledgeBase {
  // 简单的关键词匹配评分
  const scored = knowledgeBase.map(doc => {
    const words = query.toLowerCase().split(/\s+/)
    const score = words.filter(w => 
      doc.content.toLowerCase().includes(w)
    ).length
    return { doc, score }
  })
  
  scored.sort((a, b) => b.score - a.score)
  return scored.slice(0, topK).map(s => s.doc)
}

// RAG 查询
async function ragQuery(question: string): Promise<string> {
  console.log(`\n问题: ${question}`)
  
  // 1. 检索相关文档
  const relevantDocs = retrieve(question)
  console.log(`\n检索到 ${relevantDocs.length} 个相关文档:`)
  relevantDocs.forEach(doc => {
    console.log(`  - [${doc.metadata.source}] ${doc.content.slice(0, 50)}...`)
  })
  
  // 2. 构建 Prompt
  const context = relevantDocs.map(d => d.content).join("\n\n")
  const prompt = `根据以下上下文回答问题。如果上下文中没有相关信息，请说明。

上下文：
${context}

问题：${question}

回答：`

  // 3. 调用 LLM
  const response = await openai.chat.completions.create({
    model: "gpt-4o-mini",
    messages: [{ role: "user", content: prompt }],
    max_tokens: 500,
  })
  
  const answer = response.choices[0].message.content || ""
  console.log(`\n回答: ${answer}`)
  
  return answer
}

// 测试
async function main() {
  await ragQuery("OpenCode 是用什么语言写的？")
  await ragQuery("如何启动开发服务器？")
  await ragQuery("OpenCode 支持哪些 LLM？")
}

main()
```

2. 运行并观察 RAG 流程

3. 思考：
   - 检索质量如何影响最终回答？
   - 如何改进检索策略？

---

## 8. 实战项目：基于向量数据库的长期记忆

### 项目目标

构建一个具有长期记忆能力的 Agent，能够：
1. 记住用户偏好和习惯
2. 跨会话保持上下文
3. 智能检索相关记忆
4. 自动更新和遗忘过时信息

### 项目架构

```
┌─────────────────────────────────────────────────────────────┐
│                长期记忆 Agent 架构                          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │                    Agent Core                        │   │
│  │                                                     │   │
│  │  ┌───────────────┐  ┌───────────────┐              │   │
│  │  │ Memory Tools  │  │ LLM Interface │              │   │
│  │  │               │  │               │              │   │
│  │  │ • search      │  │ • chat        │              │   │
│  │  │ • store       │  │ • embed       │              │   │
│  │  │ • update      │  │               │              │   │
│  │  │ • forget      │  │               │              │   │
│  │  └───────┬───────┘  └───────────────┘              │   │
│  │          │                                          │   │
│  └──────────┼──────────────────────────────────────────┘   │
│             │                                               │
│             ▼                                               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │              Memory Manager                          │   │
│  │                                                     │   │
│  │  ┌─────────────┐  ┌─────────────┐  ┌─────────────┐ │   │
│  │  │  Embedding  │  │  Retrieval  │  │  Lifecycle  │ │   │
│  │  │  Service    │  │  Engine     │  │  Manager    │ │   │
│  │  └──────┬──────┘  └──────┬──────┘  └──────┬──────┘ │   │
│  │         │                │                │        │   │
│  └─────────┼────────────────┼────────────────┼────────┘   │
│            │                │                │             │
│            ▼                ▼                ▼             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │              Vector Database (Chroma)                │   │
│  │                                                     │   │
│  │  Collections:                                       │   │
│  │  ┌───────────┐ ┌───────────┐ ┌───────────┐         │   │
│  │  │preferences│ │ episodes  │ │   facts   │         │   │
│  │  └───────────┘ └───────────┘ └───────────┘         │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

### 实现步骤

#### 步骤 1：项目初始化

```bash
mkdir memory-agent
cd memory-agent
bun init -y
bun add openai chromadb
```

项目结构：
```
memory-agent/
├── src/
│   ├── index.ts           # 入口
│   ├── memory/
│   │   ├── types.ts       # 类型定义
│   │   ├── embedding.ts   # Embedding 服务
│   │   ├── store.ts       # 向量存储
│   │   └── manager.ts     # 记忆管理器
│   ├── agent/
│   │   ├── tools.ts       # 记忆工具
│   │   └── agent.ts       # Agent 实现
│   └── utils/
│       └── config.ts      # 配置
├── package.json
└── tsconfig.json
```

#### 步骤 2：定义记忆类型

```typescript
// src/memory/types.ts

// 记忆类型枚举
export type MemoryType = "preference" | "fact" | "episode" | "procedure"

// 记忆条目
export interface Memory {
  id: string
  content: string
  type: MemoryType
  metadata: {
    timestamp: number
    accessCount: number
    lastAccessed: number
    confidence: number
    source: "explicit" | "inferred"
    tags: string[]
  }
}

// 记忆搜索结果
export interface MemorySearchResult {
  memory: Memory
  score: number
}

// 记忆存储选项
export interface StoreOptions {
  type: MemoryType
  confidence?: number
  source?: "explicit" | "inferred"
  tags?: string[]
}

// 搜索选项
export interface SearchOptions {
  topK?: number
  type?: MemoryType
  minScore?: number
  includeMetadata?: boolean
}
```

#### 步骤 3：实现 Embedding 服务

```typescript
// src/memory/embedding.ts
import OpenAI from "openai"

export class EmbeddingService {
  private client: OpenAI
  private model: string
  
  constructor(apiKey?: string, model = "text-embedding-3-small") {
    this.client = new OpenAI({ apiKey })
    this.model = model
  }
  
  // 生成单个文本的 Embedding
  async embed(text: string): Promise<number[]> {
    const response = await this.client.embeddings.create({
      model: this.model,
      input: text,
    })
    return response.data[0].embedding
  }
  
  // 批量生成 Embedding
  async embedBatch(texts: string[]): Promise<number[][]> {
    const response = await this.client.embeddings.create({
      model: this.model,
      input: texts,
    })
    return response.data.map(d => d.embedding)
  }
}
```

#### 步骤 4：实现向量存储

```typescript
// src/memory/store.ts
import { ChromaClient, Collection } from "chromadb"
import { Memory, MemorySearchResult, SearchOptions, StoreOptions } from "./types"
import { EmbeddingService } from "./embedding"

export class MemoryStore {
  private client: ChromaClient
  private collection: Collection | null = null
  private embeddings: EmbeddingService
  private collectionName: string
  
  constructor(embeddings: EmbeddingService, collectionName = "agent_memory") {
    this.client = new ChromaClient()
    this.embeddings = embeddings
    this.collectionName = collectionName
  }
  
  // 初始化集合
  async init() {
    this.collection = await this.client.getOrCreateCollection({
      name: this.collectionName,
      metadata: { description: "Agent long-term memory" }
    })
    console.log(`Memory store initialized: ${this.collectionName}`)
  }
  
  // 存储记忆
  async store(content: string, options: StoreOptions): Promise<Memory> {
    if (!this.collection) throw new Error("Store not initialized")
    
    const id = `mem_${Date.now()}_${Math.random().toString(36).slice(2)}`
    const vector = await this.embeddings.embed(content)
    const now = Date.now()
    
    const memory: Memory = {
      id,
      content,
      type: options.type,
      metadata: {
        timestamp: now,
        accessCount: 0,
        lastAccessed: now,
        confidence: options.confidence ?? 0.8,
        source: options.source ?? "explicit",
        tags: options.tags ?? []
      }
    }
    
    await this.collection.add({
      ids: [id],
      embeddings: [vector],
      documents: [content],
      metadatas: [{
        type: memory.type,
        ...memory.metadata,
        tags: JSON.stringify(memory.metadata.tags)
      }]
    })
    
    return memory
  }
  
  // 搜索记忆
  async search(query: string, options: SearchOptions = {}): Promise<MemorySearchResult[]> {
    if (!this.collection) throw new Error("Store not initialized")
    
    const { topK = 5, type, minScore = 0.5 } = options
    const queryVector = await this.embeddings.embed(query)
    
    // 构建过滤条件
    const where = type ? { type: { $eq: type } } : undefined
    
    const results = await this.collection.query({
      queryEmbeddings: [queryVector],
      nResults: topK,
      where,
      include: ["documents", "metadatas", "distances"]
    })
    
    // 转换结果
    const memories: MemorySearchResult[] = []
    
    if (results.ids[0]) {
      for (let i = 0; i < results.ids[0].length; i++) {
        const distance = results.distances?.[0]?.[i] ?? 1
        const score = 1 - distance  // 转换距离为相似度
        
        if (score >= minScore) {
          const metadata = results.metadatas?.[0]?.[i] as any
          memories.push({
            memory: {
              id: results.ids[0][i],
              content: results.documents?.[0]?.[i] ?? "",
              type: metadata?.type ?? "fact",
              metadata: {
                timestamp: metadata?.timestamp ?? 0,
                accessCount: metadata?.accessCount ?? 0,
                lastAccessed: metadata?.lastAccessed ?? 0,
                confidence: metadata?.confidence ?? 0.8,
                source: metadata?.source ?? "explicit",
                tags: JSON.parse(metadata?.tags ?? "[]")
              }
            },
            score
          })
        }
      }
    }
    
    // 更新访问计数
    for (const result of memories) {
      await this.updateAccessCount(result.memory.id)
    }
    
    return memories
  }
  
  // 更新访问计数
  private async updateAccessCount(id: string) {
    if (!this.collection) return
    
    const existing = await this.collection.get({ ids: [id], include: ["metadatas"] })
    if (existing.metadatas?.[0]) {
      const metadata = existing.metadatas[0] as any
      await this.collection.update({
        ids: [id],
        metadatas: [{
          ...metadata,
          accessCount: (metadata.accessCount ?? 0) + 1,
          lastAccessed: Date.now()
        }]
      })
    }
  }
  
  // 删除记忆
  async delete(id: string) {
    if (!this.collection) throw new Error("Store not initialized")
    await this.collection.delete({ ids: [id] })
  }
  
  // 获取统计信息
  async stats() {
    if (!this.collection) throw new Error("Store not initialized")
    const count = await this.collection.count()
    return { count }
  }
}
```


#### 步骤 5：实现记忆管理器

```typescript
// src/memory/manager.ts
import { MemoryStore } from "./store"
import { EmbeddingService } from "./embedding"
import { Memory, MemorySearchResult, SearchOptions, StoreOptions, MemoryType } from "./types"

export class MemoryManager {
  private store: MemoryStore
  private embeddings: EmbeddingService
  
  constructor() {
    this.embeddings = new EmbeddingService()
    this.store = new MemoryStore(this.embeddings)
  }
  
  async init() {
    await this.store.init()
  }
  
  // 存储新记忆
  async remember(content: string, options: StoreOptions): Promise<Memory> {
    console.log(`[Memory] Storing: "${content.slice(0, 50)}..."`)
    return this.store.store(content, options)
  }
  
  // 检索相关记忆
  async recall(query: string, options?: SearchOptions): Promise<MemorySearchResult[]> {
    console.log(`[Memory] Recalling: "${query}"`)
    const results = await this.store.search(query, options)
    console.log(`[Memory] Found ${results.length} relevant memories`)
    return results
  }
  
  // 遗忘记忆
  async forget(id: string): Promise<void> {
    console.log(`[Memory] Forgetting: ${id}`)
    await this.store.delete(id)
  }
  
  // 应用遗忘策略
  async applyForgetPolicy(options: {
    maxAge?: number      // 最大保留天数
    minAccess?: number   // 最小访问次数
    maxCount?: number    // 最大记忆数量
  }) {
    // 这里需要实现遗忘逻辑
    // 由于 Chroma 的限制，需要先获取所有记忆再过滤
    console.log("[Memory] Applying forget policy...")
    // 实际实现略
  }
  
  // 获取统计
  async stats() {
    return this.store.stats()
  }
}
```

#### 步骤 6：实现 Agent 记忆工具

```typescript
// src/agent/tools.ts
import { MemoryManager } from "../memory/manager"
import { MemoryType } from "../memory/types"

// 工具定义（OpenAI Function Calling 格式）
export const memoryTools = [
  {
    type: "function" as const,
    function: {
      name: "memory_search",
      description: "搜索相关的记忆，用于回忆用户偏好、历史对话或事实信息",
      parameters: {
        type: "object",
        properties: {
          query: {
            type: "string",
            description: "搜索查询，描述你想要回忆的内容"
          },
          type: {
            type: "string",
            enum: ["preference", "fact", "episode", "procedure"],
            description: "记忆类型过滤（可选）"
          },
          topK: {
            type: "number",
            description: "返回结果数量，默认 5"
          }
        },
        required: ["query"]
      }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "memory_store",
      description: "存储新的记忆，用于记住用户偏好、重要事实或对话要点",
      parameters: {
        type: "object",
        properties: {
          content: {
            type: "string",
            description: "要存储的记忆内容"
          },
          type: {
            type: "string",
            enum: ["preference", "fact", "episode", "procedure"],
            description: "记忆类型"
          },
          tags: {
            type: "array",
            items: { type: "string" },
            description: "标签，用于分类和检索"
          }
        },
        required: ["content", "type"]
      }
    }
  },
  {
    type: "function" as const,
    function: {
      name: "memory_forget",
      description: "删除过时或错误的记忆",
      parameters: {
        type: "object",
        properties: {
          id: {
            type: "string",
            description: "要删除的记忆 ID"
          }
        },
        required: ["id"]
      }
    }
  }
]

// 工具执行器
export class MemoryToolExecutor {
  private manager: MemoryManager
  
  constructor(manager: MemoryManager) {
    this.manager = manager
  }
  
  async execute(name: string, args: any): Promise<string> {
    switch (name) {
      case "memory_search": {
        const results = await this.manager.recall(args.query, {
          topK: args.topK ?? 5,
          type: args.type as MemoryType
        })
        
        if (results.length === 0) {
          return "没有找到相关记忆。"
        }
        
        return results.map(r => 
          `[${r.memory.type}] (相似度: ${r.score.toFixed(2)}) ${r.memory.content}`
        ).join("\n")
      }
      
      case "memory_store": {
        const memory = await this.manager.remember(args.content, {
          type: args.type as MemoryType,
          tags: args.tags
        })
        return `已存储记忆: ${memory.id}`
      }
      
      case "memory_forget": {
        await this.manager.forget(args.id)
        return `已删除记忆: ${args.id}`
      }
      
      default:
        return `未知工具: ${name}`
    }
  }
}
```

#### 步骤 7：实现 Agent 主循环

```typescript
// src/agent/agent.ts
import OpenAI from "openai"
import { MemoryManager } from "../memory/manager"
import { memoryTools, MemoryToolExecutor } from "./tools"

export class MemoryAgent {
  private client: OpenAI
  private manager: MemoryManager
  private executor: MemoryToolExecutor
  private conversationHistory: OpenAI.Chat.ChatCompletionMessageParam[] = []
  
  constructor() {
    this.client = new OpenAI()
    this.manager = new MemoryManager()
    this.executor = new MemoryToolExecutor(this.manager)
  }
  
  async init() {
    await this.manager.init()
    
    // 系统提示
    this.conversationHistory.push({
      role: "system",
      content: `你是一个具有长期记忆能力的 AI 助手。

你可以使用以下记忆工具：
- memory_search: 搜索相关记忆，在回答问题前先检索相关信息
- memory_store: 存储重要信息，如用户偏好、关键事实
- memory_forget: 删除过时或错误的记忆

记忆类型说明：
- preference: 用户偏好（如喜欢的语言、工具）
- fact: 事实信息（如项目配置、技术栈）
- episode: 事件记录（如讨论过的话题）
- procedure: 流程知识（如部署步骤）

使用建议：
1. 在回答问题前，先搜索相关记忆
2. 当用户提供新信息时，存储为记忆
3. 发现信息过时时，更新或删除旧记忆
4. 利用记忆提供个性化的回答`
    })
  }
  
  async chat(userMessage: string): Promise<string> {
    // 添加用户消息
    this.conversationHistory.push({
      role: "user",
      content: userMessage
    })
    
    // 调用 LLM
    let response = await this.client.chat.completions.create({
      model: "gpt-4o-mini",
      messages: this.conversationHistory,
      tools: memoryTools,
      tool_choice: "auto"
    })
    
    let assistantMessage = response.choices[0].message
    
    // 处理工具调用
    while (assistantMessage.tool_calls) {
      // 添加助手消息（包含工具调用）
      this.conversationHistory.push(assistantMessage)
      
      // 执行每个工具调用
      for (const toolCall of assistantMessage.tool_calls) {
        const args = JSON.parse(toolCall.function.arguments)
        console.log(`\n[Tool] ${toolCall.function.name}:`, args)
        
        const result = await this.executor.execute(
          toolCall.function.name,
          args
        )
        console.log(`[Result] ${result}\n`)
        
        // 添加工具结果
        this.conversationHistory.push({
          role: "tool",
          tool_call_id: toolCall.id,
          content: result
        })
      }
      
      // 继续对话
      response = await this.client.chat.completions.create({
        model: "gpt-4o-mini",
        messages: this.conversationHistory,
        tools: memoryTools,
        tool_choice: "auto"
      })
      
      assistantMessage = response.choices[0].message
    }
    
    // 添加最终回复
    this.conversationHistory.push(assistantMessage)
    
    return assistantMessage.content || ""
  }
}
```

#### 步骤 8：创建入口文件

```typescript
// src/index.ts
import * as readline from "readline"
import { MemoryAgent } from "./agent/agent"

async function main() {
  console.log("初始化记忆 Agent...")
  const agent = new MemoryAgent()
  await agent.init()
  console.log("Agent 已就绪！\n")
  
  const rl = readline.createInterface({
    input: process.stdin,
    output: process.stdout
  })
  
  const prompt = () => {
    rl.question("You: ", async (input) => {
      if (input.toLowerCase() === "exit") {
        console.log("再见！")
        rl.close()
        return
      }
      
      try {
        const response = await agent.chat(input)
        console.log(`\nAssistant: ${response}\n`)
      } catch (error) {
        console.error("Error:", error)
      }
      
      prompt()
    })
  }
  
  prompt()
}

main()
```

### 运行和测试

```bash
# 启动 Chroma 服务器（如果使用本地模式可跳过）
# docker run -p 8000:8000 chromadb/chroma

# 运行 Agent
bun run src/index.ts
```

**测试对话示例**：

```
You: 我喜欢用 TypeScript 写代码


[Tool] memory_store: { content: "用户喜欢用 TypeScript 写代码", type: "preference" }
[Result] 已存储记忆: mem_1234567890_abc

Assistant: 好的，我已经记住你喜欢用 TypeScript 写代码了！

You: 帮我写一个函数

[Tool] memory_search: { query: "用户编程偏好" }
[Result] [preference] (相似度: 0.89) 用户喜欢用 TypeScript 写代码

Assistant: 我记得你喜欢 TypeScript，这是一个简单的工具函数：

\`\`\`typescript
function greet(name: string): string {
  return \`Hello, \${name}!\`
}
\`\`\`

You: 我们项目用的是 PostgreSQL 数据库

[Tool] memory_store: { content: "项目使用 PostgreSQL 数据库", type: "fact" }
[Result] 已存储记忆: mem_1234567891_def

Assistant: 好的，我记住了你们项目使用 PostgreSQL 数据库。

You: 帮我写一个数据库连接的代码

[Tool] memory_search: { query: "数据库 技术栈" }
[Result] [fact] (相似度: 0.92) 项目使用 PostgreSQL 数据库
[preference] (相似度: 0.85) 用户喜欢用 TypeScript 写代码

Assistant: 根据我的记忆，你喜欢 TypeScript，项目用 PostgreSQL。这是连接代码：

\`\`\`typescript
import { Pool } from 'pg'

const pool = new Pool({
  host: 'localhost',
  database: 'mydb',
  user: 'user',
  password: 'password',
})

export async function query(text: string, params?: any[]) {
  const result = await pool.query(text, params)
  return result.rows
}
\`\`\`
```

### 扩展思考

完成基础实现后，可以考虑以下扩展：

1. **记忆冲突检测**
   - 当新记忆与旧记忆冲突时，自动检测并处理
   - 例如：用户说"我现在用 Bun 了"，应该更新之前"用 Node.js"的记忆

2. **记忆重要性评估**
   - 根据访问频率、来源、时间等因素计算重要性
   - 在检索时优先返回重要的记忆


3. **自动记忆提取**
   - 使用 LLM 自动从对话中提取值得记忆的信息
   - 不需要用户明确说"记住这个"

4. **记忆可视化**
   - 构建一个简单的 UI 展示所有记忆
   - 支持手动编辑和删除

5. **多用户支持**
   - 为不同用户维护独立的记忆空间
   - 支持共享记忆（如项目知识）


---

## 知识补充

### 相关资源

1. **向量数据库**
   - [Chroma](https://www.trychroma.com/) - 轻量级开源向量数据库
   - [Pinecone](https://www.pinecone.io/) - 托管向量数据库服务
   - [Qdrant](https://qdrant.tech/) - 高性能开源向量数据库
   - [Milvus](https://milvus.io/) - 分布式向量数据库


2. **Embedding 模型**
   - [OpenAI Embeddings](https://platform.openai.com/docs/guides/embeddings)
   - [Cohere Embed](https://cohere.com/embed)
   - [Voyage AI](https://www.voyageai.com/)
   - [BGE Models](https://huggingface.co/BAAI/bge-m3) - 开源多语言模型

3. **RAG 框架**
   - [LangChain](https://python.langchain.com/) - 全功能 LLM 应用框架
   - [LlamaIndex](https://www.llamaindex.ai/) - 专注于 RAG 的框架
   - [Haystack](https://haystack.deepset.ai/) - 端到端 NLP 框架


4. **相关论文**
   - "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks" (RAG 原始论文)
   - "Dense Passage Retrieval for Open-Domain Question Answering"
   - "MemGPT: Towards LLMs as Operating Systems"
   - "Generative Agents: Interactive Simulacra of Human Behavior"

### 进阶阅读

- **MemGPT**：探索 LLM 作为操作系统管理记忆的方法
- **Generative Agents**：斯坦福的虚拟小镇项目，展示了复杂的记忆系统
- **LangChain Memory 文档**：了解各种记忆组件的设计和使用


---

## 本章小结

### 核心概念回顾

```
┌─────────────────────────────────────────────────────────────┐
│                    记忆系统核心概念                         │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  记忆类型：                                                 │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  • 短期记忆：当前对话上下文，受窗口限制             │   │
│  │  • 工作记忆：任务执行状态，动态更新                 │   │
│  │  • 长期记忆：持久化知识，需要检索机制               │   │
│  │  • 情景记忆：具体事件，带时间上下文                 │   │
│  │  • 语义记忆：抽象知识，不依赖具体事件               │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  向量数据库：                                               │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  • Embedding：将文本转为向量表示                    │   │
│  │  • 相似度搜索：基于语义而非关键词                   │   │
│  │  • 索引结构：HNSW、IVF 等加速检索                   │   │
│  │  • 元数据过滤：结合结构化查询                       │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  RAG 架构：                                                 │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  • 离线索引：文档分块 → Embedding → 存储            │   │
│  │  • 在线检索：查询 → 向量搜索 → 相关文档             │   │
│  │  • 增强生成：上下文 + 问题 → LLM → 回答             │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  检索策略：                                                 │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  • 相似度检索：基于向量距离                         │   │
│  │  • 时间衰减：新记忆权重更高                         │   │
│  │  • 重要性排序：访问频率、来源、置信度               │   │
│  │  • 混合检索：结合多种策略                           │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
│  生命周期管理：                                             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │  • 遗忘策略：基于时间、访问、容量、重要性           │   │
│  │  • 更新机制：检测冲突、替换或标记过时               │   │
│  │  • 合并策略：相似记忆的整合                         │   │
│  └─────────────────────────────────────────────────────┘   │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```


### 技术对照表

| 概念 | 实现方案 | 推荐工具 |
|------|----------|----------|
| Embedding | OpenAI text-embedding-3-small | OpenAI API |
| 向量存储 | Chroma / Qdrant | 开发用 Chroma，生产用 Qdrant |
| 相似度计算 | 余弦相似度 | 向量数据库内置 |
| 文档分块 | 递归分块 | LangChain TextSplitter |
| RAG 框架 | LlamaIndex / LangChain | 按需选择 |
| 记忆管理 | 自定义 MemoryManager | 参考本章实现 |


### 检查清单

完成本章学习后，你应该能够：

- [ ] 理解 Agent 记忆系统的必要性和价值
- [ ] 区分短期记忆、工作记忆和长期记忆的特点
- [ ] 解释 Embedding 的原理和语义相似度计算
- [ ] 选择合适的向量数据库方案
- [ ] 理解 RAG 的基本架构和工作流程
- [ ] 设计合理的文档分块策略
- [ ] 实现混合检索策略（相似度 + 时间 + 重要性）
- [ ] 设计记忆的遗忘和更新机制
- [ ] 构建具有长期记忆能力的 Agent


---

## 导航

- 上一章：[第四章：代码智能](./04-code-intelligence.md)
- 下一章：[第六章：可观测性与调试](./06-observability.md)
- [返回目录](./00-introduction.md)
